//! # Flow Metrics Collector Implementation\n//!\n//! This module provides comprehensive data flow monitoring and performance metrics\n//! collection system. It includes real-time throughput and latency tracking,\n//! pipeline health scoring, performance analytics, and alert systems for\n//! threshold violations.\n\nuse std::sync::{Arc, RwLock, Mutex};\nuse std::collections::{HashMap, VecDeque};\nuse std::time::{Instant, Duration, SystemTime, UNIX_EPOCH};\nuse std::sync::mpsc::{self, Sender, Receiver};\nuse serde::{Serialize, Deserialize};\n\nuse super::data_flow_coordinator::{PipelineId, FlowMetrics, PipelineHealth};\nuse super::backpressure_controller::{CongestionLevel, CongestionMetrics};\n\n/// Flow metrics collector for comprehensive data flow monitoring\npub struct FlowMetricsCollector {\n    /// Pipeline metrics storage\n    pipeline_metrics: Arc<RwLock<HashMap<PipelineId, PipelineMetrics>>>,\n    /// Real-time performance data\n    performance_data: Arc<RwLock<HashMap<PipelineId, VecDeque<PerformanceSnapshot>>>>,\n    /// Analytics engine\n    analytics: Arc<RwLock<AnalyticsEngine>>,\n    /// Alert system\n    alert_system: Arc<RwLock<AlertSystem>>,\n    /// Monitoring configuration\n    config: Arc<RwLock<MonitoringConfig>>,\n    /// Event publisher\n    event_sender: Option<Sender<MetricsEvent>>,\n    /// Collection thread handle\n    collection_active: Arc<Mutex<bool>>,\n}\n\n/// Comprehensive pipeline metrics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PipelineMetrics {\n    pub pipeline_id: PipelineId,\n    pub throughput_metrics: ThroughputMetrics,\n    pub latency_metrics: LatencyMetrics,\n    pub health_metrics: HealthMetrics,\n    pub error_metrics: ErrorMetrics,\n    pub resource_metrics: ResourceMetrics,\n    pub last_updated: SystemTime,\n}\n\n/// Throughput performance metrics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ThroughputMetrics {\n    pub current_ops_per_second: f32,\n    pub average_ops_per_second: f32,\n    pub peak_ops_per_second: f32,\n    pub total_operations: u64,\n    pub bytes_per_second: f64,\n    pub target_throughput: f32,\n    pub throughput_efficiency: f32,\n}\n\nimpl Default for ThroughputMetrics {\n    fn default() -> Self {\n        Self {\n            current_ops_per_second: 0.0,\n            average_ops_per_second: 0.0,\n            peak_ops_per_second: 0.0,\n            total_operations: 0,\n            bytes_per_second: 0.0,\n            target_throughput: 1000.0,\n            throughput_efficiency: 0.0,\n        }\n    }\n}\n\n/// Latency performance metrics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct LatencyMetrics {\n    pub current_latency_ms: f32,\n    pub average_latency_ms: f32,\n    pub min_latency_ms: f32,\n    pub max_latency_ms: f32,\n    pub p50_latency_ms: f32,\n    pub p95_latency_ms: f32,\n    pub p99_latency_ms: f32,\n    pub target_latency_ms: f32,\n    pub latency_violations: u64,\n}\n\nimpl Default for LatencyMetrics {\n    fn default() -> Self {\n        Self {\n            current_latency_ms: 0.0,\n            average_latency_ms: 0.0,\n            min_latency_ms: f32::MAX,\n            max_latency_ms: 0.0,\n            p50_latency_ms: 0.0,\n            p95_latency_ms: 0.0,\n            p99_latency_ms: 0.0,\n            target_latency_ms: 2.0,\n            latency_violations: 0,\n        }\n    }\n}\n\n/// Pipeline health metrics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct HealthMetrics {\n    pub health_score: f32,          // 0.0-1.0\n    pub health_status: PipelineHealth,\n    pub uptime_percentage: f32,\n    pub availability_score: f32,\n    pub reliability_score: f32,\n    pub performance_score: f32,\n    pub last_health_check: SystemTime,\n    pub health_trend: HealthTrend,\n}\n\nimpl Default for HealthMetrics {\n    fn default() -> Self {\n        Self {\n            health_score: 1.0,\n            health_status: PipelineHealth::Healthy,\n            uptime_percentage: 100.0,\n            availability_score: 1.0,\n            reliability_score: 1.0,\n            performance_score: 1.0,\n            last_health_check: SystemTime::now(),\n            health_trend: HealthTrend::Stable,\n        }\n    }\n}\n\n/// Health trend indicators\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum HealthTrend {\n    Improving,\n    Stable,\n    Degrading,\n    Critical,\n}\n\n/// Error and failure metrics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ErrorMetrics {\n    pub total_errors: u64,\n    pub error_rate_percentage: f32,\n    pub errors_per_minute: f32,\n    pub recent_errors: VecDeque<ErrorEvent>,\n    pub error_categories: HashMap<String, u64>,\n    pub recovery_time_ms: f32,\n    pub mtbf_hours: f32,            // Mean Time Between Failures\n    pub mttr_minutes: f32,          // Mean Time To Recovery\n}\n\nimpl Default for ErrorMetrics {\n    fn default() -> Self {\n        Self {\n            total_errors: 0,\n            error_rate_percentage: 0.0,\n            errors_per_minute: 0.0,\n            recent_errors: VecDeque::new(),\n            error_categories: HashMap::new(),\n            recovery_time_ms: 0.0,\n            mtbf_hours: 0.0,\n            mttr_minutes: 0.0,\n        }\n    }\n}\n\n/// Resource utilization metrics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ResourceMetrics {\n    pub memory_usage_bytes: u64,\n    pub cpu_utilization: f32,\n    pub buffer_utilization: f32,\n    pub queue_length: usize,\n    pub resource_efficiency: f32,\n    pub resource_pressure: ResourcePressure,\n}\n\nimpl Default for ResourceMetrics {\n    fn default() -> Self {\n        Self {\n            memory_usage_bytes: 0,\n            cpu_utilization: 0.0,\n            buffer_utilization: 0.0,\n            queue_length: 0,\n            resource_efficiency: 1.0,\n            resource_pressure: ResourcePressure::Low,\n        }\n    }\n}\n\n/// Resource pressure levels\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum ResourcePressure {\n    Low,\n    Moderate,\n    High,\n    Critical,\n}\n\n/// Performance snapshot for analytics\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PerformanceSnapshot {\n    pub timestamp: SystemTime,\n    pub throughput_ops_per_second: f32,\n    pub latency_ms: f32,\n    pub error_rate: f32,\n    pub resource_utilization: f32,\n    pub health_score: f32,\n}\n\n/// Analytics engine for trend analysis\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AnalyticsEngine {\n    pub trend_analysis: TrendAnalysis,\n    pub performance_benchmarks: PerformanceBenchmarks,\n    pub predictive_models: PredictiveModels,\n    pub anomaly_detection: AnomalyDetection,\n}\n\nimpl Default for AnalyticsEngine {\n    fn default() -> Self {\n        Self {\n            trend_analysis: TrendAnalysis::default(),\n            performance_benchmarks: PerformanceBenchmarks::default(),\n            predictive_models: PredictiveModels::default(),\n            anomaly_detection: AnomalyDetection::default(),\n        }\n    }\n}\n\n/// Trend analysis data\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TrendAnalysis {\n    pub throughput_trend: TrendDirection,\n    pub latency_trend: TrendDirection,\n    pub error_trend: TrendDirection,\n    pub health_trend: TrendDirection,\n    pub trend_confidence: f32,\n    pub trend_duration_minutes: f32,\n}\n\nimpl Default for TrendAnalysis {\n    fn default() -> Self {\n        Self {\n            throughput_trend: TrendDirection::Stable,\n            latency_trend: TrendDirection::Stable,\n            error_trend: TrendDirection::Stable,\n            health_trend: TrendDirection::Stable,\n            trend_confidence: 0.5,\n            trend_duration_minutes: 0.0,\n        }\n    }\n}\n\n/// Trend direction indicators\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum TrendDirection {\n    Improving,\n    Stable,\n    Degrading,\n    Unknown,\n}\n\n/// Performance benchmarks\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PerformanceBenchmarks {\n    pub baseline_throughput: f32,\n    pub baseline_latency: f32,\n    pub target_throughput: f32,\n    pub target_latency: f32,\n    pub sla_throughput: f32,\n    pub sla_latency: f32,\n    pub benchmark_last_updated: SystemTime,\n}\n\nimpl Default for PerformanceBenchmarks {\n    fn default() -> Self {\n        Self {\n            baseline_throughput: 1000.0,\n            baseline_latency: 2.0,\n            target_throughput: 1000.0,\n            target_latency: 2.0,\n            sla_throughput: 800.0,\n            sla_latency: 5.0,\n            benchmark_last_updated: SystemTime::now(),\n        }\n    }\n}\n\n/// Predictive modeling for performance forecasting\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PredictiveModels {\n    pub load_prediction: LoadPrediction,\n    pub failure_prediction: FailurePrediction,\n    pub capacity_prediction: CapacityPrediction,\n    pub model_accuracy: f32,\n}\n\nimpl Default for PredictiveModels {\n    fn default() -> Self {\n        Self {\n            load_prediction: LoadPrediction::default(),\n            failure_prediction: FailurePrediction::default(),\n            capacity_prediction: CapacityPrediction::default(),\n            model_accuracy: 0.8,\n        }\n    }\n}\n\n/// Load prediction model\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct LoadPrediction {\n    pub predicted_throughput: f32,\n    pub predicted_latency: f32,\n    pub prediction_horizon_minutes: u32,\n    pub confidence_interval: f32,\n}\n\nimpl Default for LoadPrediction {\n    fn default() -> Self {\n        Self {\n            predicted_throughput: 1000.0,\n            predicted_latency: 2.0,\n            prediction_horizon_minutes: 30,\n            confidence_interval: 0.8,\n        }\n    }\n}\n\n/// Failure prediction model\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FailurePrediction {\n    pub failure_probability: f32,\n    pub time_to_failure_minutes: f32,\n    pub failure_risk_level: RiskLevel,\n    pub contributing_factors: Vec<String>,\n}\n\nimpl Default for FailurePrediction {\n    fn default() -> Self {\n        Self {\n            failure_probability: 0.0,\n            time_to_failure_minutes: f32::INFINITY,\n            failure_risk_level: RiskLevel::Low,\n            contributing_factors: Vec::new(),\n        }\n    }\n}\n\n/// Capacity prediction model\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CapacityPrediction {\n    pub capacity_utilization: f32,\n    pub time_to_capacity_minutes: f32,\n    pub recommended_scaling: ScalingRecommendation,\n    pub capacity_trend: TrendDirection,\n}\n\nimpl Default for CapacityPrediction {\n    fn default() -> Self {\n        Self {\n            capacity_utilization: 0.5,\n            time_to_capacity_minutes: f32::INFINITY,\n            recommended_scaling: ScalingRecommendation::None,\n            capacity_trend: TrendDirection::Stable,\n        }\n    }\n}\n\n/// Risk levels for predictions\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum RiskLevel {\n    Low,\n    Medium,\n    High,\n    Critical,\n}\n\n/// Scaling recommendations\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum ScalingRecommendation {\n    None,\n    ScaleUp,\n    ScaleDown,\n    ScaleOut,\n    OptimizeConfig,\n}\n\n/// Anomaly detection system\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AnomalyDetection {\n    pub anomalies_detected: Vec<Anomaly>,\n    pub detection_sensitivity: f32,\n    pub false_positive_rate: f32,\n    pub detection_algorithms: Vec<String>,\n}\n\nimpl Default for AnomalyDetection {\n    fn default() -> Self {\n        Self {\n            anomalies_detected: Vec::new(),\n            detection_sensitivity: 0.8,\n            false_positive_rate: 0.05,\n            detection_algorithms: vec![\n                \"statistical_outlier\".to_string(),\n                \"trend_deviation\".to_string(),\n                \"pattern_anomaly\".to_string(),\n            ],\n        }\n    }\n}\n\n/// Detected anomaly\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Anomaly {\n    pub anomaly_type: AnomalyType,\n    pub severity: AnomalySeverity,\n    pub confidence: f32,\n    pub detected_at: SystemTime,\n    pub description: String,\n    pub affected_metrics: Vec<String>,\n}\n\n/// Types of anomalies\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum AnomalyType {\n    PerformanceDegradation,\n    ThroughputAnomaly,\n    LatencySpike,\n    ErrorRateIncrease,\n    ResourceExhaustion,\n    PatternDeviation,\n}\n\n/// Anomaly severity levels\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum AnomalySeverity {\n    Info,\n    Warning,\n    Critical,\n    Emergency,\n}\n\n/// Alert system for threshold violations\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AlertSystem {\n    pub active_alerts: HashMap<String, Alert>,\n    pub alert_rules: Vec<AlertRule>,\n    pub notification_channels: Vec<NotificationChannel>,\n    pub alert_history: VecDeque<Alert>,\n}\n\nimpl Default for AlertSystem {\n    fn default() -> Self {\n        Self {\n            active_alerts: HashMap::new(),\n            alert_rules: Vec::new(),\n            notification_channels: Vec::new(),\n            alert_history: VecDeque::new(),\n        }\n    }\n}\n\n/// Performance alert definition\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Alert {\n    pub id: String,\n    pub alert_type: AlertType,\n    pub severity: AlertSeverity,\n    pub message: String,\n    pub triggered_at: SystemTime,\n    pub pipeline_id: PipelineId,\n    pub current_value: f32,\n    pub threshold_value: f32,\n    pub acknowledged: bool,\n}\n\n/// Alert types\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum AlertType {\n    ThroughputThreshold,\n    LatencyThreshold,\n    ErrorRateThreshold,\n    HealthScoreThreshold,\n    ResourceUtilization,\n    AnomalyDetected,\n}\n\n/// Alert severity levels\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum AlertSeverity {\n    Info,\n    Warning,\n    Critical,\n    Emergency,\n}\n\n/// Alert rule configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AlertRule {\n    pub rule_id: String,\n    pub alert_type: AlertType,\n    pub threshold: f32,\n    pub comparison: ComparisonOperator,\n    pub evaluation_window_seconds: u64,\n    pub cooldown_seconds: u64,\n    pub enabled: bool,\n}\n\n/// Comparison operators for alert rules\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum ComparisonOperator {\n    GreaterThan,\n    LessThan,\n    Equal,\n    GreaterThanOrEqual,\n    LessThanOrEqual,\n}\n\n/// Notification channel configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct NotificationChannel {\n    pub channel_id: String,\n    pub channel_type: ChannelType,\n    pub enabled: bool,\n    pub severity_filter: Vec<AlertSeverity>,\n}\n\n/// Notification channel types\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum ChannelType {\n    Console,\n    EventBus,\n    WebSocket,\n    Custom(String),\n}\n\n/// Monitoring configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MonitoringConfig {\n    pub collection_interval_ms: u64,\n    pub retention_period_hours: u64,\n    pub snapshot_interval_seconds: u64,\n    pub analytics_enabled: bool,\n    pub anomaly_detection_enabled: bool,\n    pub predictive_modeling_enabled: bool,\n    pub alert_system_enabled: bool,\n}\n\nimpl Default for MonitoringConfig {\n    fn default() -> Self {\n        Self {\n            collection_interval_ms: 100,\n            retention_period_hours: 24,\n            snapshot_interval_seconds: 10,\n            analytics_enabled: true,\n            anomaly_detection_enabled: true,\n            predictive_modeling_enabled: false,\n            alert_system_enabled: true,\n        }\n    }\n}\n\n/// Error event for tracking\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ErrorEvent {\n    pub timestamp: SystemTime,\n    pub error_type: String,\n    pub error_message: String,\n    pub severity: ErrorSeverity,\n}\n\n/// Error severity levels\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub enum ErrorSeverity {\n    Low,\n    Medium,\n    High,\n    Critical,\n}\n\n/// Metrics events for publishing\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum MetricsEvent {\n    MetricsUpdated {\n        pipeline_id: PipelineId,\n        metrics: PipelineMetrics,\n    },\n    ThresholdViolation {\n        pipeline_id: PipelineId,\n        alert: Alert,\n    },\n    AnomalyDetected {\n        pipeline_id: PipelineId,\n        anomaly: Anomaly,\n    },\n    TrendChange {\n        pipeline_id: PipelineId,\n        trend: TrendAnalysis,\n    },\n    HealthStatusChange {\n        pipeline_id: PipelineId,\n        old_status: PipelineHealth,\n        new_status: PipelineHealth,\n    },\n}\n\nimpl FlowMetricsCollector {\n    /// Create a new flow metrics collector\n    pub fn new() -> Self {\n        Self {\n            pipeline_metrics: Arc::new(RwLock::new(HashMap::new())),\n            performance_data: Arc::new(RwLock::new(HashMap::new())),\n            analytics: Arc::new(RwLock::new(AnalyticsEngine::default())),\n            alert_system: Arc::new(RwLock::new(AlertSystem::default())),\n            config: Arc::new(RwLock::new(MonitoringConfig::default())),\n            event_sender: None,\n            collection_active: Arc::new(Mutex::new(false)),\n        }\n    }\n    \n    /// Set event sender for metrics notifications\n    pub fn set_event_sender(&mut self, sender: Sender<MetricsEvent>) {\n        self.event_sender = Some(sender);\n    }\n    \n    /// Start metrics collection for a pipeline\n    pub fn start_monitoring(&mut self, pipeline_id: PipelineId) {\n        // Initialize pipeline metrics\n        let metrics = PipelineMetrics {\n            pipeline_id: pipeline_id.clone(),\n            throughput_metrics: ThroughputMetrics::default(),\n            latency_metrics: LatencyMetrics::default(),\n            health_metrics: HealthMetrics::default(),\n            error_metrics: ErrorMetrics::default(),\n            resource_metrics: ResourceMetrics::default(),\n            last_updated: SystemTime::now(),\n        };\n        \n        if let Ok(mut pipeline_metrics) = self.pipeline_metrics.write() {\n            pipeline_metrics.insert(pipeline_id.clone(), metrics);\n        }\n        \n        // Initialize performance data storage\n        if let Ok(mut performance_data) = self.performance_data.write() {\n            performance_data.insert(pipeline_id, VecDeque::with_capacity(1000));\n        }\n    }\n    \n    /// Update pipeline metrics with new data\n    pub fn update_metrics(\n        &mut self,\n        pipeline_id: &PipelineId,\n        throughput_ops_per_second: f32,\n        latency_ms: f32,\n        error_count: u64,\n        resource_utilization: f32,\n    ) {\n        if let Ok(mut pipeline_metrics) = self.pipeline_metrics.write() {\n            if let Some(metrics) = pipeline_metrics.get_mut(pipeline_id) {\n                // Update throughput metrics\n                self.update_throughput_metrics(&mut metrics.throughput_metrics, throughput_ops_per_second);\n                \n                // Update latency metrics\n                self.update_latency_metrics(&mut metrics.latency_metrics, latency_ms);\n                \n                // Update error metrics\n                self.update_error_metrics(&mut metrics.error_metrics, error_count);\n                \n                // Update resource metrics\n                self.update_resource_metrics(&mut metrics.resource_metrics, resource_utilization);\n                \n                // Update health metrics\n                self.update_health_metrics(&mut metrics.health_metrics, &metrics);\n                \n                metrics.last_updated = SystemTime::now();\n                \n                // Create performance snapshot\n                self.create_performance_snapshot(pipeline_id, &metrics);\n                \n                // Check for alerts\n                self.check_alert_conditions(pipeline_id, &metrics);\n                \n                // Publish metrics event\n                self.publish_metrics_event(MetricsEvent::MetricsUpdated {\n                    pipeline_id: pipeline_id.clone(),\n                    metrics: metrics.clone(),\n                });\n            }\n        }\n    }\n    \n    /// Update throughput metrics\n    fn update_throughput_metrics(&self, metrics: &mut ThroughputMetrics, current_ops: f32) {\n        metrics.current_ops_per_second = current_ops;\n        metrics.average_ops_per_second = 0.9 * metrics.average_ops_per_second + 0.1 * current_ops;\n        metrics.peak_ops_per_second = metrics.peak_ops_per_second.max(current_ops);\n        metrics.total_operations += current_ops as u64;\n        metrics.throughput_efficiency = (current_ops / metrics.target_throughput).min(1.0);\n    }\n    \n    /// Update latency metrics\n    fn update_latency_metrics(&self, metrics: &mut LatencyMetrics, current_latency: f32) {\n        metrics.current_latency_ms = current_latency;\n        metrics.average_latency_ms = 0.9 * metrics.average_latency_ms + 0.1 * current_latency;\n        metrics.min_latency_ms = metrics.min_latency_ms.min(current_latency);\n        metrics.max_latency_ms = metrics.max_latency_ms.max(current_latency);\n        \n        // Update percentiles (simplified calculation)\n        metrics.p50_latency_ms = metrics.average_latency_ms;\n        metrics.p95_latency_ms = metrics.average_latency_ms * 1.5;\n        metrics.p99_latency_ms = metrics.average_latency_ms * 2.0;\n        \n        if current_latency > metrics.target_latency_ms {\n            metrics.latency_violations += 1;\n        }\n    }\n    \n    /// Update error metrics\n    fn update_error_metrics(&self, metrics: &mut ErrorMetrics, error_count: u64) {\n        let previous_errors = metrics.total_errors;\n        metrics.total_errors = error_count;\n        \n        if error_count > previous_errors {\n            metrics.error_rate_percentage = \n                (error_count as f32 / metrics.total_errors.max(1) as f32) * 100.0;\n            metrics.errors_per_minute += 1.0;\n        }\n    }\n    \n    /// Update resource metrics\n    fn update_resource_metrics(&self, metrics: &mut ResourceMetrics, utilization: f32) {\n        metrics.resource_efficiency = 1.0 - utilization;\n        metrics.buffer_utilization = utilization;\n        \n        metrics.resource_pressure = match utilization {\n            x if x > 0.9 => ResourcePressure::Critical,\n            x if x > 0.7 => ResourcePressure::High,\n            x if x > 0.5 => ResourcePressure::Moderate,\n            _ => ResourcePressure::Low,\n        };\n    }\n    \n    /// Update health metrics\n    fn update_health_metrics(&self, health: &mut HealthMetrics, metrics: &PipelineMetrics) {\n        // Calculate composite health score\n        let throughput_score = metrics.throughput_metrics.throughput_efficiency;\n        let latency_score = if metrics.latency_metrics.current_latency_ms > 0.0 {\n            (metrics.latency_metrics.target_latency_ms / metrics.latency_metrics.current_latency_ms).min(1.0)\n        } else {\n            1.0\n        };\n        let error_score = 1.0 - (metrics.error_metrics.error_rate_percentage / 100.0);\n        let resource_score = metrics.resource_metrics.resource_efficiency;\n        \n        health.health_score = (throughput_score + latency_score + error_score + resource_score) / 4.0;\n        health.performance_score = (throughput_score + latency_score) / 2.0;\n        health.reliability_score = error_score;\n        health.availability_score = resource_score;\n        \n        // Update health status\n        let previous_status = health.health_status.clone();\n        health.health_status = match health.health_score {\n            x if x >= 0.9 => PipelineHealth::Healthy,\n            x if x >= 0.7 => PipelineHealth::Degraded,\n            x if x >= 0.5 => PipelineHealth::Critical,\n            _ => PipelineHealth::Failed,\n        };\n        \n        health.last_health_check = SystemTime::now();\n        \n        // Determine health trend\n        // (Simplified - in practice would analyze historical data)\n        health.health_trend = if health.health_score > 0.8 {\n            HealthTrend::Stable\n        } else if health.health_score < 0.5 {\n            HealthTrend::Critical\n        } else {\n            HealthTrend::Degrading\n        };\n        \n        // Publish health status change event\n        if previous_status != health.health_status {\n            self.publish_metrics_event(MetricsEvent::HealthStatusChange {\n                pipeline_id: metrics.pipeline_id.clone(),\n                old_status: previous_status,\n                new_status: health.health_status.clone(),\n            });\n        }\n    }\n    \n    /// Create performance snapshot for analytics\n    fn create_performance_snapshot(&self, pipeline_id: &PipelineId, metrics: &PipelineMetrics) {\n        let snapshot = PerformanceSnapshot {\n            timestamp: SystemTime::now(),\n            throughput_ops_per_second: metrics.throughput_metrics.current_ops_per_second,\n            latency_ms: metrics.latency_metrics.current_latency_ms,\n            error_rate: metrics.error_metrics.error_rate_percentage,\n            resource_utilization: metrics.resource_metrics.buffer_utilization,\n            health_score: metrics.health_metrics.health_score,\n        };\n        \n        if let Ok(mut performance_data) = self.performance_data.write() {\n            if let Some(snapshots) = performance_data.get_mut(pipeline_id) {\n                snapshots.push_back(snapshot);\n                \n                // Limit snapshot history size\n                if snapshots.len() > 1000 {\n                    snapshots.pop_front();\n                }\n            }\n        }\n    }\n    \n    /// Check alert conditions and trigger alerts\n    fn check_alert_conditions(&self, pipeline_id: &PipelineId, metrics: &PipelineMetrics) {\n        // Check throughput threshold\n        if metrics.throughput_metrics.current_ops_per_second < 800.0 {\n            let alert = Alert {\n                id: format!(\"throughput_{}\", pipeline_id.0),\n                alert_type: AlertType::ThroughputThreshold,\n                severity: AlertSeverity::Warning,\n                message: \"Throughput below threshold\".to_string(),\n                triggered_at: SystemTime::now(),\n                pipeline_id: pipeline_id.clone(),\n                current_value: metrics.throughput_metrics.current_ops_per_second,\n                threshold_value: 800.0,\n                acknowledged: false,\n            };\n            \n            self.trigger_alert(alert);\n        }\n        \n        // Check latency threshold\n        if metrics.latency_metrics.current_latency_ms > 5.0 {\n            let alert = Alert {\n                id: format!(\"latency_{}\", pipeline_id.0),\n                alert_type: AlertType::LatencyThreshold,\n                severity: AlertSeverity::Critical,\n                message: \"Latency above threshold\".to_string(),\n                triggered_at: SystemTime::now(),\n                pipeline_id: pipeline_id.clone(),\n                current_value: metrics.latency_metrics.current_latency_ms,\n                threshold_value: 5.0,\n                acknowledged: false,\n            };\n            \n            self.trigger_alert(alert);\n        }\n        \n        // Check health score threshold\n        if metrics.health_metrics.health_score < 0.7 {\n            let alert = Alert {\n                id: format!(\"health_{}\", pipeline_id.0),\n                alert_type: AlertType::HealthScoreThreshold,\n                severity: AlertSeverity::Warning,\n                message: \"Health score below threshold\".to_string(),\n                triggered_at: SystemTime::now(),\n                pipeline_id: pipeline_id.clone(),\n                current_value: metrics.health_metrics.health_score,\n                threshold_value: 0.7,\n                acknowledged: false,\n            };\n            \n            self.trigger_alert(alert);\n        }\n    }\n    \n    /// Trigger an alert\n    fn trigger_alert(&self, alert: Alert) {\n        if let Ok(mut alert_system) = self.alert_system.write() {\n            alert_system.active_alerts.insert(alert.id.clone(), alert.clone());\n            alert_system.alert_history.push_back(alert.clone());\n            \n            // Limit alert history size\n            if alert_system.alert_history.len() > 100 {\n                alert_system.alert_history.pop_front();\n            }\n        }\n        \n        self.publish_metrics_event(MetricsEvent::ThresholdViolation {\n            pipeline_id: alert.pipeline_id.clone(),\n            alert,\n        });\n    }\n    \n    /// Publish metrics event\n    fn publish_metrics_event(&self, event: MetricsEvent) {\n        if let Some(sender) = &self.event_sender {\n            let _ = sender.send(event);\n        }\n    }\n    \n    /// Get pipeline metrics\n    pub fn get_pipeline_metrics(&self, pipeline_id: &PipelineId) -> Option<PipelineMetrics> {\n        if let Ok(pipeline_metrics) = self.pipeline_metrics.read() {\n            pipeline_metrics.get(pipeline_id).cloned()\n        } else {\n            None\n        }\n    }\n    \n    /// Get all pipeline metrics\n    pub fn get_all_metrics(&self) -> HashMap<PipelineId, PipelineMetrics> {\n        if let Ok(pipeline_metrics) = self.pipeline_metrics.read() {\n            pipeline_metrics.clone()\n        } else {\n            HashMap::new()\n        }\n    }\n    \n    /// Get performance snapshots for analytics\n    pub fn get_performance_snapshots(&self, pipeline_id: &PipelineId) -> Vec<PerformanceSnapshot> {\n        if let Ok(performance_data) = self.performance_data.read() {\n            performance_data.get(pipeline_id)\n                .map(|snapshots| snapshots.iter().cloned().collect())\n                .unwrap_or_default()\n        } else {\n            Vec::new()\n        }\n    }\n    \n    /// Get active alerts\n    pub fn get_active_alerts(&self) -> Vec<Alert> {\n        if let Ok(alert_system) = self.alert_system.read() {\n            alert_system.active_alerts.values().cloned().collect()\n        } else {\n            Vec::new()\n        }\n    }\n    \n    /// Acknowledge alert\n    pub fn acknowledge_alert(&mut self, alert_id: &str) -> bool {\n        if let Ok(mut alert_system) = self.alert_system.write() {\n            if let Some(alert) = alert_system.active_alerts.get_mut(alert_id) {\n                alert.acknowledged = true;\n                return true;\n            }\n        }\n        false\n    }\n    \n    /// Clear acknowledged alerts\n    pub fn clear_acknowledged_alerts(&mut self) {\n        if let Ok(mut alert_system) = self.alert_system.write() {\n            alert_system.active_alerts.retain(|_, alert| !alert.acknowledged);\n        }\n    }\n}\n\nimpl Default for FlowMetricsCollector {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn test_metrics_collector_creation() {\n        let collector = FlowMetricsCollector::new();\n        assert!(collector.pipeline_metrics.read().unwrap().is_empty());\n    }\n    \n    #[test]\n    fn test_pipeline_monitoring_start() {\n        let mut collector = FlowMetricsCollector::new();\n        let pipeline_id = PipelineId(\"test\".to_string());\n        \n        collector.start_monitoring(pipeline_id.clone());\n        \n        let metrics = collector.get_pipeline_metrics(&pipeline_id);\n        assert!(metrics.is_some());\n        assert_eq!(metrics.unwrap().pipeline_id, pipeline_id);\n    }\n    \n    #[test]\n    fn test_metrics_update() {\n        let mut collector = FlowMetricsCollector::new();\n        let pipeline_id = PipelineId(\"test\".to_string());\n        \n        collector.start_monitoring(pipeline_id.clone());\n        collector.update_metrics(&pipeline_id, 1200.0, 1.5, 0, 0.3);\n        \n        let metrics = collector.get_pipeline_metrics(&pipeline_id).unwrap();\n        assert_eq!(metrics.throughput_metrics.current_ops_per_second, 1200.0);\n        assert_eq!(metrics.latency_metrics.current_latency_ms, 1.5);\n    }\n    \n    #[test]\n    fn test_health_score_calculation() {\n        let mut collector = FlowMetricsCollector::new();\n        let pipeline_id = PipelineId(\"test\".to_string());\n        \n        collector.start_monitoring(pipeline_id.clone());\n        collector.update_metrics(&pipeline_id, 1000.0, 2.0, 0, 0.5);\n        \n        let metrics = collector.get_pipeline_metrics(&pipeline_id).unwrap();\n        assert!(metrics.health_metrics.health_score > 0.8);\n        assert_eq!(metrics.health_metrics.health_status, PipelineHealth::Healthy);\n    }\n    \n    #[test]\n    fn test_performance_snapshots() {\n        let mut collector = FlowMetricsCollector::new();\n        let pipeline_id = PipelineId(\"test\".to_string());\n        \n        collector.start_monitoring(pipeline_id.clone());\n        collector.update_metrics(&pipeline_id, 1000.0, 2.0, 0, 0.5);\n        \n        let snapshots = collector.get_performance_snapshots(&pipeline_id);\n        assert_eq!(snapshots.len(), 1);\n        assert_eq!(snapshots[0].throughput_ops_per_second, 1000.0);\n    }\n}